{"cells":[{"cell_type":"markdown","source":["Local Connection-guided Contrastive Leanning (L-CoCL)\n","---\n","* Implement (G-CoCL) with the same code\n","* https://github.com/sayakpaul/Supervised-Contrastive-Learning-in-TensorFlow-2"],"metadata":{"id":"mCNwIILcWXOS"},"id":"mCNwIILcWXOS"},{"cell_type":"code","source":["from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import losses\n","import time\n","import tensorflow as tf\n","import os\n","import keras\n","import random\n","import pickle"],"metadata":{"id":"cDdX0wMfIMwe"},"id":"cDdX0wMfIMwe","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"15d55991","metadata":{"id":"15d55991"},"outputs":[],"source":["with open(\"L_CoCL_label.pickle\", 'rb') as f:\n","    DATA = pickle.load(f)"]},{"cell_type":"code","source":["mirrored_strategy = tf.distribute.MirroredStrategy()"],"metadata":{"id":"XhLGvnPkHbhX"},"id":"XhLGvnPkHbhX","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f522f789","metadata":{"id":"f522f789"},"outputs":[],"source":["import numpy as np\n","import math\n","from tensorflow.keras.utils import Sequence\n","\n","spec = DATA['specEEG']\n","labels = DATA['LABEL']\n","\n","class CustomDataset(tf.keras.utils.Sequence):\n","    def __init__(self,specEEG,labels,batch_size,target_size=(1, 55, 114),shuffle=False,n_classes=1):\n","        self.batch_size = batch_size\n","        self.dim        = target_size\n","        self.labels     = labels\n","        self.specEEG   = specEEG\n","        self.n_classes  = n_classes\n","        self.shuffle    = shuffle\n","        self.c          = 0\n","        self.on_epoch_end() \n","\n","    def __len__(self):\n","        # returns the number of batches\n","        return int(np.floor(len(self.specEEG) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        # returns one batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # Generate data\n","        X, X_aug, y = self.__data_generation(indexes)\n","        return X, X_aug, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.specEEG))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def timeshift(self, spec, shift=3, direction='right', roll=True):\n","        direction_list= ['right', 'left']\n","        direction = random.choice(direction_list)\n","        spec = spec.copy()\n","        if direction == 'right':\n","            right_slice = spec[:, -shift:, :].copy()\n","            spec[:, shift:, :] = spec[:, :-shift, :]\n","            if roll:\n","                spec[:, :shift, :] = np.fliplr(right_slice)\n","        if direction == 'left':\n","            left_slice = spec[:, :shift, :].copy()\n","            spec[:, :-shift, :] = spec[:, shift:, :]\n","            if roll:\n","                spec[:, -shift:, :] = left_slice\n","        return spec\n","    \n","    def block_masking(self, spec, T=5, F=3, time_mask_num=1, freq_mask_num=1):\n","        feat_size = spec.shape[1] #59\n","        seq_len = spec.shape[2] #114\n","        for _ in range(time_mask_num):\n","            t = np.random.uniform(low=0.0, high=T)\n","            t = int(t)\n","            t0 = random.randint(0, seq_len - t)\n","            for _ in range(freq_mask_num):\n","                f = np.random.uniform(low=0.0, high=F)\n","                f = int(f)\n","                f0 = random.randint(0, feat_size - f)\n","                \n","                spec[:,t0 : t0 + t, f0 : f0 + f] = 0\n","        return spec      \n","    \n","    def spec_augment(self, spec, T=5, F=3, time_mask_num=1, freq_mask_num=1):\n","        feat_size = spec.shape[1]\n","        seq_len = spec.shape[2]\n","        # freq mask\n","        for _ in range(time_mask_num):\n","            t = np.random.uniform(low=0.0, high=T)\n","            t = int(t)\n","            t0 = random.randint(0, seq_len - t)\n","            spec[:,t0 : t0 + t,:] = 0\n","        # time mask\n","        for _ in range(freq_mask_num):\n","            f = np.random.uniform(low=0.0, high=F)\n","            f = int(f)\n","            f0 = random.randint(0, feat_size - f)\n","            spec[:, :, f0 : f0 + f] = 0\n","        return spec            \n","    \n","    def __data_generation(self, list_IDs_temp):\n","        X = np.empty((self.batch_size, *self.dim))\n","        X_aug = np.empty((self.batch_size, *self.dim))\n","        y = np.empty((self.batch_size), dtype=int)\n","        augment_list= ['spec_augment', 'time_shift', 'block_masking']\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            augment = random.choice(augment_list)\n","            # Store sample\n","            spec   = self.specEEG [ID]\n","            if augment == 'spec_augment':\n","                spec_aug = self.spec_augment(spec)\n","            if augment == 'time_shift':\n","                spec_aug = self.timeshift(spec)\n","            if augment == 'block_masking':\n","                spec_aug = self.block_masking(spec)\n","            X[i,]  = spec\n","            X_aug[i,] = spec_aug\n","            \n","            # Store class\n","            y[i] = self.labels[ID]\n","\n","            self.c +=1\n","        return X, X_aug, y\n","    \n","class Generator(keras.utils.Sequence):\n","    \"\"\"Wrapper of two generatos for the combined input model\"\"\"\n","\n","    def __init__(self, X, Y, batch_size,target_size=(1, 55, 114)):\n","        self.genX = CustomDataset(X, Y, batch_size=batch_size,shuffle=False,target_size=target_size)\n","\n","    def __len__(self):\n","        return self.genX.__len__()\n","\n","    def __getitem__(self, index):\n","        X_batch, X_batch_aug, Y_batch = self.genX.__getitem__(index)\n","        \n","        return X_batch, X_batch_aug, Y_batch\n","\n","Data_loader = Generator(spec,labels,batch_size=1024)"]},{"cell_type":"code","execution_count":null,"id":"afd6828a","metadata":{"id":"afd6828a"},"outputs":[],"source":["def encoderModel():\n","    input_shape=(1,55, 114)\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same',data_format= \"channels_first\",  activation='relu'))\n","    model.add(Conv2D(1,  (3, 3), padding='same',data_format= \"channels_first\",  activation='relu'))\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"28675640","metadata":{"id":"28675640"},"outputs":[],"source":["class UnitNormLayer(tf.keras.layers.Layer):\n","    '''Normalize vectors (euclidean norm) in batch to unit hypersphere.\n","    '''\n","    def __init__(self):\n","        super(UnitNormLayer, self).__init__()\n","\n","    def call(self, input_tensor):\n","        norm = tf.norm(input_tensor, axis=1)\n","        return input_tensor / tf.reshape(norm, [-1, 1])"]},{"cell_type":"code","execution_count":null,"id":"a11079fd","metadata":{"id":"a11079fd"},"outputs":[],"source":["# Encoder Network\n","def encoder_net():\n","    inputs = Input((1,55, 114))\n","    normalization_layer = UnitNormLayer()\n","\n","    encoder = encoderModel()\n","    encoder.trainable = True\n","\n","    embeddings = encoder(inputs, training=True)\n","    embeddings = GlobalAveragePooling2D()(embeddings)\n","    norm_embeddings = normalization_layer(embeddings)\n","    encoder_network = Model(inputs, norm_embeddings)\n","\n","    return encoder_network\n","\n","# Projector Network\n","def projector_net():\n","    projector = tf.keras.models.Sequential([\n","        Flatten(),\n","        Dense(64, activation=\"relu\"),\n","        Dense(32, activation=\"relu\"),\n","#         UnitNormLayer()\n","        \n","    ])\n","    return projector"]},{"cell_type":"code","execution_count":null,"id":"f8139bb5","metadata":{"id":"f8139bb5"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam()\n","with mirrored_strategy.scope():\n","    encoder_r = encoder_net()\n","    projector_z = projector_net()\n","\n","@tf.function\n","def train_step(images, images_aug, labels):\n","    with tf.GradientTape() as tape:\n","        r = encoder_r(images, training=True)\n","        z = projector_z(r, training=True)\n","\n","        r_aug = encoder_r(images_aug, training=True)\n","        z_aug = projector_z(r_aug, training=True)\n","\n","        loss = losses.max_margin_contrastive_loss_aug(z, z_aug, labels, metric='cosine')\n","        \n","    gradients = tape.gradient(loss, encoder_r.trainable_variables + projector_z.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, encoder_r.trainable_variables + projector_z.trainable_variables))\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"id":"3d9eddad","metadata":{"id":"3d9eddad"},"outputs":[],"source":["@tf.function\n","def distributed_train_step(spec, spec_aug, label):\n","    per_replica_losses = mirrored_strategy.run(train_step, args=(spec, spec_aug, label))\n","    return mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n","                         axis=None)"]},{"cell_type":"code","source":["EPOCHS = 60\n","LOG_EVERY = 10\n","train_loss_results = []\n","\n","train_log_dir = 'pre-trained_model_dir/L-CoCL/'\n","\n","for epoch in tqdm(range(EPOCHS)):\n","    epoch_loss_avg = tf.keras.metrics.Mean()\n","    for (spec, spec_aug, label) in Data_loader:\n","        loss = distributed_train_step(spec, spec_aug, label)\n","        epoch_loss_avg.update_state(loss) \n","    train_loss_results.append(epoch_loss_avg.result())\n","    if epoch % LOG_EVERY == 0:\n","        print(\"Epoch: {} Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n","\n","if not os.path.exists(train_log_dir):\n","    os.makedirs(train_log_dir)\n","a = 'encoder.h5' \n","b = 'projecter.h5'   \n","encoder_r.save(os.path.join(train_log_dir, a))\n","projector_z.save(os.path.join(train_log_dir, b))\n","\n","with plt.xkcd():\n","    plt.plot(train_loss_results)\n","    plt.title(\"L-CoCL Loss\")\n","    plt.show()"],"metadata":{"id":"EbxbheVEH623"},"id":"EbxbheVEH623","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}