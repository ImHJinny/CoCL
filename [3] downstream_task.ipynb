{"cells":[{"cell_type":"code","execution_count":null,"id":"1f154b0a","metadata":{"id":"1f154b0a"},"outputs":[],"source":["from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.callbacks import EarlyStopping\n","from random import shuffle\n","import math\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import losses\n","import time\n","import tensorflow as tf\n","import os\n","import keras\n","import pandas as pd\n","import pickle"]},{"cell_type":"code","execution_count":null,"id":"7fb9babf","metadata":{"id":"7fb9babf"},"outputs":[],"source":["with open(\"downstream_labeling_data.pickle\", 'rb') as f:\n","    DATA = pickle.load(f)"]},{"cell_type":"code","source":["mirrored_strategy = tf.distribute.MirroredStrategy()"],"metadata":{"id":"8m1e_flH9tx0"},"id":"8m1e_flH9tx0","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"1e899ef3","metadata":{"id":"1e899ef3","outputId":"80f35680-c112-49e4-d5fe-71691a035260"},"outputs":[{"data":{"text/plain":["(1, 1, 22, 55, 114)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["DATA[\"specEEG\"][0].shape"]},{"cell_type":"code","execution_count":null,"id":"df1863da","metadata":{"id":"df1863da"},"outputs":[],"source":["class CustomDataset(tf.keras.utils.Sequence):\n","    def __init__(self,specEEG,labels,batch_size,target_size=(1, 55, 114),shuffle=False,n_classes=1):\n","        self.batch_size = batch_size\n","        self.dim        = target_size\n","        self.labels     = labels\n","        self.specEEG   = specEEG\n","        self.n_classes  = n_classes\n","        self.shuffle    = shuffle\n","        self.c          = 0\n","        self.on_epoch_end() \n","\n","    def __len__(self):\n","        # returns the number of batches\n","        return int(np.floor(len(self.specEEG) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        # returns one batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # Generate data\n","        X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21, y = self.__data_generation(indexes)\n","        return X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.specEEG))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    \n","    def __data_generation(self, list_IDs_temp):\n","        for i in range(22):\n","            globals()['X%d'%i] = np.empty((self.batch_size, *self.dim))\n","        y = np.empty((self.batch_size), dtype=int)\n","        \n","        X_list = [X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21]\n","        \n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            spec   = self.specEEG[ID]\n","            for Xnum, X in enumerate(X_list):\n","                X[i,]  = spec[0][0][Xnum]\n","\n","            # Store class\n","            y[i] = self.labels[ID]\n","\n","            self.c +=1\n","        return X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21,  y #keras.utils.to_categorical(y, num_classes=self.n_classes)\n","\n","    \n","class Generator(keras.utils.Sequence):\n","    \"\"\"Wrapper of two generatos for the combined input model\"\"\"\n","\n","    def __init__(self, X, Y, batch_size,target_size=(1, 55, 114)):\n","        self.genX = CustomDataset(X, Y, batch_size=batch_size,shuffle=False,target_size=target_size)\n","\n","    def __len__(self):\n","        return self.genX.__len__()\n","\n","    def __getitem__(self, index):\n","        X1_batch, X2_batch, X3_batch, X4_batch, X5_batch, X6_batch, X7_batch, X8_batch, X9_batch, X10_batch, X11_batch, X12_batch, X13_batch, X14_batch, X15_batch, X16_batch, X17_batch, X18_batch, X19_batch, X20_batch, X21_batch, X22_batch,Y_batch = self.genX.__getitem__(index)\n","        \n","        return [X1_batch, X2_batch, X3_batch, X4_batch, X5_batch, X6_batch, X7_batch, X8_batch, X9_batch, X10_batch, X11_batch, X12_batch, X13_batch, X14_batch, X15_batch, X16_batch,  X17_batch, X18_batch, X19_batch, X20_batch, X21_batch, X22_batch], Y_batch"]},{"cell_type":"code","source":["def createModel_L_G_CoCL():\n","    pre_encoder = keras.models.load_model('./saved_models/SCL_model/L_CoCL/model.h5')\n","    pre_encoder2 = keras.models.load_model('./saved_models/SCL_model/G_CoCL/model.h5')\n","    pre_encoder.trainable = True\n","    pre_encoder2.trainable = True\n","\n","    pre_encoder._name = 'model1'\n","    pre_encoder2._name = 'model2'\n","\n","    inp1  = Input(shape=(1,55,114))\n","    h1 = pre_encoder(inp1,training=True)\n","    h1_ = pre_encoder2(inp1,training=True)\n","\n","    inp2  = Input(shape=(1,55,114))\n","    h2 = pre_encoder(inp2,training=True)\n","    h2_ = pre_encoder2(inp2,training=True)\n","\n","    inp3  = Input(shape=(1,55,114))\n","    h3 = pre_encoder(inp3,training=True)\n","    h3_ = pre_encoder2(inp3,training=True)\n","\n","    inp4  = Input(shape=(1,55,114))\n","    h4 = pre_encoder(inp4,training=True)\n","    h4_ = pre_encoder2(inp4,training=True)\n","\n","    inp5  = Input(shape=(1,55,114))\n","    h5 = pre_encoder(inp5,training=True)\n","    h5_ = pre_encoder2(inp5,training=True)\n","\n","    inp6  = Input(shape=(1,55,114))\n","    h6 = pre_encoder(inp6,training=True)\n","    h6_ = pre_encoder2(inp6,training=True)\n","\n","    inp7  = Input(shape=(1,55,114))\n","    h7 = pre_encoder(inp7,training=True) \n","    h7_ = pre_encoder2(inp7,training=True)   \n","\n","    inp8  = Input(shape=(1,55,114))\n","    h8 = pre_encoder(inp8,training=True)\n","    h8_ = pre_encoder2(inp8,training=True)\n","\n","    inp9  = Input(shape=(1,55,114))\n","    h9 = pre_encoder(inp9,training=True)\n","    h9_ = pre_encoder2(inp9,training=True)\n","\n","    inp10  = Input(shape=(1,55,114))\n","    h10 = pre_encoder(inp10,training=True)\n","    h10_ = pre_encoder2(inp10,training=True)\n","\n","    inp11  = Input(shape=(1,55,114))\n","    h11 = pre_encoder(inp11,training=True)\n","    h11_ = pre_encoder2(inp11,training=True)\n","\n","    inp12  = Input(shape=(1,55,114))\n","    h12 = pre_encoder(inp12,training=True)\n","    h12_ = pre_encoder2(inp12,training=True)\n","\n","    inp13  = Input(shape=(1,55,114))\n","    h13 = pre_encoder(inp13,training=True)\n","    h13_ = pre_encoder2(inp13,training=True)\n","\n","    inp14  = Input(shape=(1,55,114))\n","    h14 = pre_encoder(inp14,training=True)\n","    h14_ = pre_encoder2(inp14,training=True)  \n","\n","    inp15  = Input(shape=(1,55,114))\n","    h15 = pre_encoder(inp15,training=True)\n","    h15_ = pre_encoder2(inp15,training=True)\n","\n","    inp16  = Input(shape=(1,55,114))\n","    h16 = pre_encoder(inp16,training=True)\n","    h16_ = pre_encoder2(inp16,training=True)\n","\n","    inp17  = Input(shape=(1,55,114))\n","    h17 = pre_encoder(inp17,training=True)\n","    h17_ = pre_encoder2(inp17,training=True)\n","\n","    inp18  = Input(shape=(1,55,114))\n","    h18 = pre_encoder(inp18,training=True)\n","    h18_ = pre_encoder2(inp18,training=True)\n","\n","    inp19  = Input(shape=(1,55,114))\n","    h19 = pre_encoder(inp19,training=True)\n","    h19_ = pre_encoder2(inp19,training=True)\n","\n","    inp20  = Input(shape=(1,55,114))\n","    h20 = pre_encoder(inp20,training=True)\n","    h20_ = pre_encoder2(inp20,training=True)\n","\n","    inp21  = Input(shape=(1,55,114))\n","    h21 = pre_encoder(inp21,training=True)\n","    h21_ = pre_encoder2(inp21,training=True)\n","\n","    inp22  = Input(shape=(1,55,114)) \n","    h22 = pre_encoder(inp22,training=True)\n","    h22_ = pre_encoder2(inp22,training=True)\n","\n","    concat1 = Concatenate(axis=-3)([h1, h2, h3, h4, h5, h6, h7, h8, h9, h10, h11, h12, h13, h14, h15, h16, h17, h18, h19, h20, h21, h22])\n","    concat2 = Concatenate(axis=-3)([h1_, h2_, h3_, h4_, h5_, h6_, h7_, h8_, h9_, h10_, h11_, h12_, h13_, h14_, h15_, h16_, h17_, h18_, h19_, h20_, h21_, h22])\n","\n","    reshape1 = Reshape((1, 22, 55, 114))(concat1)\n","    reshape2 = Reshape((1, 22, 55, 114))(concat2)\n","\n","    \n","    #C1\n","    lay1 = Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\")(reshape1)\n","    lay1_ = Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\")(reshape2)\n","    lay2 = keras.layers.MaxPooling3D(pool_size=(1, 2, 2),data_format= \"channels_first\",  padding='same')(lay1)\n","    lay2_ = keras.layers.MaxPooling3D(pool_size=(1, 2, 2),data_format= \"channels_first\",  padding='same')(lay1_)\n","    lay3 = BatchNormalization()(lay2)\n","    lay3_ = BatchNormalization()(lay2_)\n","    \n","    #C2\n","    lay4 = Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu')(lay3)\n","    lay4_ = Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu')(lay3_)#incertezza se togliere padding\n","    lay5 = keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", )(lay4)\n","    lay5_ = keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", )(lay4_)\n","    lay6 = BatchNormalization()(lay5)\n","    lay6_ = BatchNormalization()(lay5_)\n","    \n","    #C3\n","    lay7 =Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu')(lay6)\n","    lay7_ =Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu')(lay6_)#incertezza se togliere padding\n","    lay8 =keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", )(lay7)\n","    lay8_ =keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", )(lay7_)\n","    lay9 =BatchNormalization()(lay8)\n","    lay9_ =BatchNormalization()(lay8_)\n","    \n","    lay10 = Flatten()(lay9)\n","    lay10_ = Flatten()(lay9_)\n","    concat = Concatenate()([lay10,lay10_])\n","    \n","    lay11 = Dense(256, activation='linear')(concat)\n","    ouputs = Dense(1, activation='sigmoid')(lay11)\n","    \n","    ftmodel = Model([inp1, inp2, inp3, inp4, inp5, inp6, inp7, inp8, inp9, inp10, inp11, inp12, inp13, inp14, inp15, inp16, inp17, inp18, inp19, inp20, inp21, inp22], outputs=ouputs)\n","    \n","    opt_adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","    ftmodel.compile(loss='BinaryCrossentropy', optimizer=opt_adam, metrics=['accuracy'])\n","    \n","    return ftmodel"],"metadata":{"id":"qP8ih1IEV4VI"},"id":"qP8ih1IEV4VI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_dir = './saved_models/SCL_fine_tuning/'\n","\n","historys = {}\n","\n","from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","def to_one_or_zero(bool):\n","    return 1 if bool else 0\n","\n","patients = [\"01\", \"02\", \"03\", \"05\", \"09\", \"10\", \"18\", \"21\", \"23\"]\n","\n","target_sensitive = []\n","target_accuracy = []\n","target_specificity = []\n","for i in range(len(patients)):\n","    sen = []\n","    acc = []\n","    spe = []\n","    \n","    DATA_s = pd.DataFrame(DATA)\n","    DATA_set = DATA_s[DATA_s[\"numPAZ\"] == patients[i]]\n","\n","    spec = DATA_set['specEEG']\n","    labels = DATA_set['LABEL']\n","    spec   = np.array(spec)\n","    labels = np.array(labels)\n","    \n","    for index, (train_indices, val_indices) in enumerate(skf.split(spec, labels)):\n","        print(\"Training on fold \" + str(index+1))\n","        X_train, X_val = spec[train_indices], spec[val_indices]\n","        y_train, y_val = labels[train_indices],labels[val_indices]\n","        print(X_train.shape, y_train.shape,X_val.shape, y_val.shape)\n","\n","        TRAIN = Generator(X_train,y_train,batch_size=64,target_size=(1, 55, 114))\n","        VALID = Generator(X_val,y_val,batch_size=64,target_size=(1, 55, 114))\n","        \n","        with mirrored_strategy.scope():\n","            model = createModel_L_G_CoCL()\n","        \n","        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'auto')\n","        checkpointer = keras.callbacks.ModelCheckpoint(save_dir+patients[i]+'model.h5', monitor='val_loss',verbose=1, save_best_only=True, save_weights_only =True)\n","\n","        # FIT THE MODEL\n","        history = model.fit(TRAIN,\n","            epochs=150,\n","            validation_data=VALID,\n","            callbacks=[checkpointer, early_stopping])\n","\n","        historys= history.history\n","        \n","        X_test = DATA_test['specEEG']\n","        y_test = DATA_test['LABEL']\n","        X_test   = np.array(X_test)\n","        y_test = np.array(y_test)\n","    \n","        VALID_ = Generator(X_test,y_test,batch_size=1,target_size=(1, 55, 114))\n","        y_scores = model.predict(VALID_)\n","        y_scores = list(map(to_one_or_zero, y_scores > .5))\n","        con_mat = tf.math.confusion_matrix(labels=y_test[:len(y_scores)], predictions=y_scores).numpy()\n","        sensi = con_mat[1][1]/(con_mat[1][1]+con_mat[1][0])\n","        speci = con_mat[0][0]/(con_mat[0][0]+con_mat[0][1])\n","        accu = (con_mat[0][0]+con_mat[1][1])/(con_mat[0][0]+con_mat[0][1]+con_mat[1][0]+con_mat[1][1])\n","        sen.append(sensi)\n","        spe.append(speci)\n","        acc.append(accu)\n","        print(\"sen : \",sensi)\n","        print(\"spe : \",speci)\n","        print(\"acc : \",accu)\n","        print(con_mat)  \n","        \n","    target_sen = np.mean(sen)\n","    target_spe = np.mean(spe)\n","    target_acc = np.mean(acc)\n","    sen_std = np.std(sen)\n","    spe_std = np.std(spe)\n","    acc_std = np.std(acc)\n","    print('target_sen:',target_sen, sen_std)\n","    print('target_spe:',target_spe, spe_std)\n","    print('target_acc:',target_acc, acc_std)\n","    target_sensitive.append(target_sen)\n","    target_specificity.append(target_spe)\n","    target_accuracy.append(target_acc)"],"metadata":{"id":"5YnR8_tET00B"},"id":"5YnR8_tET00B","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}